{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41aI2NeWo2IL",
        "outputId": "7cd81e1f-8f1b-44f3-a070-2c2ad7e77832"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.28.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.4-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.3/70.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (269 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.4/269.4 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.4 yarl-1.9.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.9/dist-packages (0.42.1)\n"
          ]
        }
      ],
      "source": [
        "# 安装依赖\n",
        "!pip install transformers\n",
        "!pip install openai\n",
        "!pip install jieba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8UFD-L8ajoOs"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from argparse import Namespace\n",
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
        "\n",
        "\n",
        "# Mean Pooling - Take attention mask into account for correct averaging\n",
        "def mean_pooling(model_output, attention_mask):\n",
        "    token_embeddings = model_output[0]  # First element of model_output contains all token embeddings\n",
        "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
        "\n",
        "\n",
        "# Load model from HuggingFace Hub\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MWYK5PBY8j1"
      },
      "outputs": [],
      "source": [
        "model_names = [\n",
        "    'shibing624/text2vec-base-chinese',\n",
        "    'silk-road/luotuo-bert',\n",
        "    'GanymedeNil/text2vec-large-chinese'\n",
        "]\n",
        "\n",
        "# 测试句向量\n",
        "\n",
        "texts = [\n",
        "    \"今天天气很好\",\n",
        "    \"今天天气很差\",\n",
        "    \"今天天气晴朗，万里无云\"\n",
        "]\n",
        "model_args = Namespace(do_mlm=None, pooler_type=\"cls\", temp=0.05, mlp_only_train=False, init_embeddings_model=None)\n",
        "\n",
        "for name in model_names:\n",
        "  print(name)\n",
        "  if name == 'silk-road/luotuo-bert':\n",
        "    model = AutoModel.from_pretrained(name,trust_remote_code=True,model_args=model_args)\n",
        "  else:\n",
        "    model = AutoModel.from_pretrained(name,trust_remote_code=True)\n",
        "  tokenizer = AutoTokenizer.from_pretrained(name)\n",
        "\n",
        "  encoded_input = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    if name == 'silk-road/luotuo-bert':\n",
        "      sentence_embeddings = model(**encoded_input, output_hidden_states=True, return_dict=True, sent_emb=True).pooler_output\n",
        "    else:    \n",
        "      model_output = model(**encoded_input)\n",
        "      # Perform pooling. In this case, max pooling.\n",
        "      sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
        "\n",
        "\n",
        "  # 计算余弦相似度  [-1, 1]，值越高，越相似\n",
        "  # Cosine similarities are in [-1, 1]. Higher means more similar\n",
        "  print(torch.nn.functional.cosine_similarity(sentence_embeddings[0], sentence_embeddings[1], dim=0))\n",
        "  print(torch.nn.functional.cosine_similarity(sentence_embeddings[0], sentence_embeddings[2], dim=0))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8p3dJqCfKwp"
      },
      "outputs": [],
      "source": [
        "!pip install text2vec"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "sys.path.append('..')\n",
        "from text2vec import SentenceModel\n",
        "from text2vec import Word2Vec\n",
        "import numpy as np\n",
        "\n",
        "def cosine_similarity(x, y):\n",
        "    return np.dot(x, y) / (np.linalg.norm(x) * np.linalg.norm(y))\n",
        "\n",
        "def compute_emb(model,name):\n",
        "  print(name) \n",
        "  sentence_embeddings = model.encode(texts)\n",
        "  print(type(sentence_embeddings), sentence_embeddings.shape)\n",
        "\n",
        "  print(cosine_similarity(sentence_embeddings[0], sentence_embeddings[1]))\n",
        "  print(cosine_similarity(sentence_embeddings[0], sentence_embeddings[2]))\n",
        "\n",
        "\n",
        "# 中文句向量模型(CoSENT)，中文语义匹配任务推荐，支持fine-tune继续训练\n",
        "t2v_model = SentenceModel(\"shibing624/text2vec-base-chinese\")\n",
        "compute_emb(t2v_model,'shibing624/text2vec-base-chinese')\n",
        "\n",
        "# 支持多语言的句向量模型（Sentence-BERT），英文语义匹配任务推荐，支持fine-tune继续训练\n",
        "sbert_model = SentenceModel(\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
        "compute_emb(sbert_model,'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
        "\n",
        "# 中文词向量模型(word2vec)，中文字面匹配任务和冷启动适用\n",
        "w2v_model = Word2Vec(\"w2v-light-tencent-chinese\")\n",
        "compute_emb(w2v_model,'w2v-light-tencent-chinese')\n"
      ],
      "metadata": {
        "id": "ApIrO79mqsAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import jieba\n",
        "\n",
        "# 手工用词向量表示句子，并计算相似度\n",
        "embedings = []\n",
        "for text in texts:\n",
        "  seg_list = jieba.cut(text, cut_all=False) # 精确模式\n",
        "  words = \" \".join(seg_list).split(\" \")\n",
        "  embed = []\n",
        "  for w in words:\n",
        "    if w == \"，\":\n",
        "      continue\n",
        "    embed.append(w2v_model.encode(w))\n",
        "  matrix = np.array(embed)\n",
        "  # 沿着行的方向计算平均值\n",
        "  mean = np.mean(matrix, axis=0)\n",
        "  embedings.append(mean)\n",
        "\n",
        "print(cosine_similarity(embedings[0], embedings[1]))\n",
        "print(cosine_similarity(embedings[0], embedings[2]))"
      ],
      "metadata": {
        "id": "ccxUthFvvWOq",
        "outputId": "d55a21ad-0a53-45a4-a137-749118eb5565",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9204265172093801\n",
            "0.7687565139133027\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# openai 计算句向量\n",
        "!pip install openai[embeddings]\n"
      ],
      "metadata": {
        "id": "2BOU1MYjyz07",
        "outputId": "524ed627-94c1-4f76-a211-69260f7bba22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai[embeddings]\n",
            "  Downloading openai-0.27.4-py3-none-any.whl (70 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/70.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.3/70.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai[embeddings]) (4.65.0)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai[embeddings]) (2.27.1)\n",
            "Collecting pandas-stubs>=1.1.0.11\n",
            "  Downloading pandas_stubs-2.0.0.230412-py3-none-any.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.9/dist-packages (from openai[embeddings]) (1.2.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.9/dist-packages (from openai[embeddings]) (5.13.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from openai[embeddings]) (1.10.1)\n",
            "Requirement already satisfied: tenacity>=8.0.1 in /usr/local/lib/python3.9/dist-packages (from openai[embeddings]) (8.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from openai[embeddings]) (1.22.4)\n",
            "Requirement already satisfied: openpyxl>=3.0.7 in /usr/local/lib/python3.9/dist-packages (from openai[embeddings]) (3.0.10)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from openai[embeddings]) (3.7.1)\n",
            "Requirement already satisfied: pandas>=1.2.3 in /usr/local/lib/python3.9/dist-packages (from openai[embeddings]) (1.5.3)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.9/dist-packages (from openpyxl>=3.0.7->openai[embeddings]) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.2.3->openai[embeddings]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.2.3->openai[embeddings]) (2022.7.1)\n",
            "Collecting types-pytz>=2022.1.1\n",
            "  Downloading types_pytz-2023.3.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai[embeddings]) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai[embeddings]) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai[embeddings]) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai[embeddings]) (2.0.12)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0.2->openai[embeddings]) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0.2->openai[embeddings]) (1.2.0)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (269 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.4/269.4 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai[embeddings]) (23.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->openai[embeddings]) (23.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->openai[embeddings]) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->openai[embeddings]) (3.0.9)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->openai[embeddings]) (5.12.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->openai[embeddings]) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->openai[embeddings]) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->openai[embeddings]) (4.39.3)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->openai[embeddings]) (8.4.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->openai[embeddings]) (3.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas>=1.2.3->openai[embeddings]) (1.16.0)\n",
            "Installing collected packages: types-pytz, pandas-stubs, multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.4 pandas-stubs-2.0.0.230412 types-pytz-2023.3.0.0 yarl-1.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "openai.api_key = \"sk-\"  # 输入你自己的api key\n",
        "\n",
        "\n",
        "\n",
        "model_ids = [\n",
        "    # 'gpt-3.5-turbo', # 这个模型不支持embeding\n",
        "    'text-embedding-ada-002',\n",
        "    \"text-similarity-davinci-001\",\n",
        "    \"text-search-ada-doc-001\"\n",
        "]\n",
        "for model_id in model_ids:\n",
        "  embedings = []\n",
        "  for text in texts:\n",
        "    embedding = openai.Embedding.create(input=text, model=model_id)['data'][0]['embedding'] # 浮点数组\n",
        "    print(\"len\",len(embedding))\n",
        "    embedings.append(np.array(embedding))\n",
        "\n",
        "  print(model_id)\n",
        "  print(cosine_similarity(embedings[0], embedings[1]))\n",
        "  print(cosine_similarity(embedings[0], embedings[2]))"
      ],
      "metadata": {
        "id": "ly2nVW8O0M3n",
        "outputId": "34c92a8b-d2c3-422e-92ed-769f9c3b0dea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len 1536\n",
            "len 1536\n",
            "len 1536\n",
            "text-embedding-ada-002\n",
            "0.9297494324102838\n",
            "0.9159156752383093\n",
            "len 12288\n",
            "len 12288\n",
            "len 12288\n",
            "text-similarity-davinci-001\n",
            "0.8640324273741014\n",
            "0.9050137753062327\n",
            "len 1024\n",
            "len 1024\n",
            "len 1024\n",
            "text-search-ada-doc-001\n",
            "0.974462972994041\n",
            "0.890246260231079\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 测试 llama\n",
        "! wget https://huggingface.co/Mabbs/chinese-Alpaca-lora-7b-ggml/resolve/main/ggml-model-q4_0.bin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3Ho231QCvot",
        "outputId": "007b6e18-babb-4cb2-e242-02847e04c0ea"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-27 04:49:28--  https://huggingface.co/Mabbs/chinese-Alpaca-lora-7b-ggml/resolve/main/ggml-model-q4_0.bin\n",
            "Resolving huggingface.co (huggingface.co)... 13.249.85.92, 13.249.85.127, 13.249.85.69, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.249.85.92|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/ef/d3/efd3bb2456cfd758cef490dcd8acb14c5aa5c7a9cae386d3b7447f6b41b3a32a/399d858ec1e45f277c9a7c61a9cd7dbbed0aa2a357c92a6fd478b3c5bbf803e1?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27ggml-model-q4_0.bin%3B+filename%3D%22ggml-model-q4_0.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1682830169&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL3JlcG9zL2VmL2QzL2VmZDNiYjI0NTZjZmQ3NThjZWY0OTBkY2Q4YWNiMTRjNWFhNWM3YTljYWUzODZkM2I3NDQ3ZjZiNDFiM2EzMmEvMzk5ZDg1OGVjMWU0NWYyNzdjOWE3YzYxYTljZDdkYmJlZDBhYTJhMzU3YzkyYTZmZDQ3OGIzYzViYmY4MDNlMT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE2ODI4MzAxNjl9fX1dfQ__&Signature=jfggTaRDLH2IUGen%7EDao9NxzTiVigux9n2fGg-EsVm-xVaqjHB4v1iVJCj4mHSFB2QHe2v0Qqzffp18aKpJlV1gc%7EIjwz%7EW7gHL7dvQiquW7V-eL1IzYuw2cX-t1HRDQ1QSQLpSMJq-c--r2pNPpPcPrtP5zFY%7EfOvNKN5xOMi2xGy3v1W249vUzkXmdyQNQfI9mrNOPjluDCpGdVcPOqKA1ZCqIOdEIVwiT8geLPuQta47IoyKstKd-Tl9mYsSp1n4OuSnKdoJ%7ETHtuNFcByNdlABoiKc0eNmXb8uqri5wGc8x5PcVmL5d56bDHepCs7y4lQcg9BJa9C6J6EG0pdQ__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
            "--2023-04-27 04:49:29--  https://cdn-lfs.huggingface.co/repos/ef/d3/efd3bb2456cfd758cef490dcd8acb14c5aa5c7a9cae386d3b7447f6b41b3a32a/399d858ec1e45f277c9a7c61a9cd7dbbed0aa2a357c92a6fd478b3c5bbf803e1?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27ggml-model-q4_0.bin%3B+filename%3D%22ggml-model-q4_0.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1682830169&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL3JlcG9zL2VmL2QzL2VmZDNiYjI0NTZjZmQ3NThjZWY0OTBkY2Q4YWNiMTRjNWFhNWM3YTljYWUzODZkM2I3NDQ3ZjZiNDFiM2EzMmEvMzk5ZDg1OGVjMWU0NWYyNzdjOWE3YzYxYTljZDdkYmJlZDBhYTJhMzU3YzkyYTZmZDQ3OGIzYzViYmY4MDNlMT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE2ODI4MzAxNjl9fX1dfQ__&Signature=jfggTaRDLH2IUGen%7EDao9NxzTiVigux9n2fGg-EsVm-xVaqjHB4v1iVJCj4mHSFB2QHe2v0Qqzffp18aKpJlV1gc%7EIjwz%7EW7gHL7dvQiquW7V-eL1IzYuw2cX-t1HRDQ1QSQLpSMJq-c--r2pNPpPcPrtP5zFY%7EfOvNKN5xOMi2xGy3v1W249vUzkXmdyQNQfI9mrNOPjluDCpGdVcPOqKA1ZCqIOdEIVwiT8geLPuQta47IoyKstKd-Tl9mYsSp1n4OuSnKdoJ%7ETHtuNFcByNdlABoiKc0eNmXb8uqri5wGc8x5PcVmL5d56bDHepCs7y4lQcg9BJa9C6J6EG0pdQ__&Key-Pair-Id=KVTP0A1DKRTAX\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 54.230.18.98, 54.230.18.21, 54.230.18.111, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|54.230.18.98|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4305023808 (4.0G) [application/octet-stream]\n",
            "Saving to: ‘ggml-model-q4_0.bin’\n",
            "\n",
            "ggml-model-q4_0.bin 100%[===================>]   4.01G  93.9MB/s    in 45s     \n",
            "\n",
            "2023-04-27 04:50:14 (92.0 MB/s) - ‘ggml-model-q4_0.bin’ saved [4305023808/4305023808]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-cpp-python\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFXw607SDFJ4",
        "outputId": "44c28474-e6f4-421a-956d-d6997c5f395b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting llama-cpp-python\n",
            "  Downloading llama_cpp_python-0.1.38.tar.gz (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.9/dist-packages (from llama-cpp-python) (4.5.0)\n",
            "Building wheels for collected packages: llama-cpp-python\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.1.38-cp39-cp39-linux_x86_64.whl size=164837 sha256=7b4c41d6ac0d49c66282f24660747630895157214d9696a3641415ba2dac52fc\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/2d/67/6f8385807f0fe541d2fe6ce446c3d5e75984828a7f6f09c992\n",
            "Successfully built llama-cpp-python\n",
            "Installing collected packages: llama-cpp-python\n",
            "Successfully installed llama-cpp-python-0.1.38\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_cpp import Llama\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def cosine_similarity(x, y):\n",
        "    return np.dot(x, y) / (np.linalg.norm(x) * np.linalg.norm(y))\n",
        "\n",
        "llm = Llama(model_path='./ggml-model-q4_0.bin', embedding=True)\n",
        "\n",
        "embedings = []\n",
        "for text in texts:\n",
        "  embedding = llm.create_embedding(text)['data'][0]['embedding']\n",
        "  print(\"len\",len(embedding))\n",
        "  embedings.append(np.array(embedding))\n",
        "\n",
        "print(cosine_similarity(embedings[0], embedings[1]))\n",
        "print(cosine_similarity(embedings[0], embedings[2]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8Biz5MqDigR",
        "outputId": "e81b5207-f225-449f-ebb5-98a261b4ff5b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | VSX = 0 | \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len 4096\n",
            "len 4096\n",
            "len 4096\n",
            "0.8367674190917038\n",
            "0.583370587132951\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}